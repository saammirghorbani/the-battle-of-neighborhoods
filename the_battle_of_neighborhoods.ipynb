{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHPteVhAjvSf"
   },
   "source": [
    "# Using Data Science to find the best place to live in Sydney\n",
    "*The Battle of Neighborhoods - IBM Data Science Capstone Project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mW3wGGQZTZYy"
   },
   "source": [
    "## Introduction\n",
    "Sydney is a fast growing city with over 600 suburbs and has been high up on the list for most liveable cities in the world for several years. It is no suprise that many people dream of visiting or starting a life in Sydney. \n",
    "\n",
    "In 2019 I had the privledge of going on exchange to Sydney for one semester, and I can safely say that it is a great place to be! However, it is also one of the most expensive cities in the world, and with so many suburbs it is hard to know which places that one should consider when choosing where to live. This is where the idea for this project started. \n",
    "\n",
    "What if we could use Data Science to recommend which places would be of interest for someone planning on moving to Sydney, or even just choosing a place to stay temporarily?\n",
    "\n",
    "In this project, the goal is to make suggestions based on three main factors*:\n",
    "* Proximity to recommended venues.\n",
    "* Living expenses.\n",
    "* Safety.\n",
    "\n",
    "___\n",
    "\n",
    "\\**DISCLAIMER: I do not encourage anyone to make their decisions based on the findings in this report alone. There are many more factors to consider than are captured in the scope of this project.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RNqyeOsU_Dg"
   },
   "source": [
    "## Data\n",
    "The data for this project will be gathered from various sources using API calls, web scraping and publicly available datasets. \n",
    "\n",
    "### Proximity to recommended venues\n",
    "Foursquare API will be used for gathering information about the most popular venue types in each suburb. This will be done to recommend the most suitable places to live based on a stakeholder's venues of interest.\n",
    "\n",
    "Australian post codes with coordinates https://www.matthewproctor.com/australian_postcodes. Australia Post charges for using their dataset. Instead, a regularly updated, community maintained dataset will be used for this project. Sydney suburb names with coordinates will be extracted from this dataset and then used with the Foursquare API to list venues in each suburb for recommendation.\n",
    "\n",
    "### Living expenses\n",
    "The median house value in each suburb will be web scraped from http://house.speakingsame.com/suburbtop.php?sta=nsw&cat=HomePrice&name=. Geojson data will be gathered from https://data.gov.au/dataset/ds-dga-91e70237-d9d1-4719-a82f-e71b811154c6/details which contains suburb names and boundary coordinates. This will be used for visualizing suburbs with boundaries. The geojson data will then be used together with the median house values to get an overview of which areas are less or more expensive to live in Sydney. \n",
    "\n",
    "### Safety\n",
    "Crime reports in CSV format from 2019 for every Local Government Area (LGA) in Sydney was retrieved from the NSW Bureau of Crime Statistics and Research https://www.bocsar.nsw.gov.au/Pages/bocsar_crime_stats/bocsar_latest_quarterly_and_annual_reports.aspx. This will be done so that a stakeholder can find the safest regions in Sydney. LGA geojson was gathered from https://data.gov.au/dataset/ds-dga-f6a00643-1842-48cd-9c2f-df23a3a1dc1e/details to use for visualizing areas in a choropleth map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dTNbSQhzJkq"
   },
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing necessary libraries and select the coordinates for Sydney that the map visualizations will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXfTMToxqqtg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "# If folium is not installed\n",
    "#!conda install -c conda-forge folium --yes\n",
    "import folium\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# display all dataframe rows\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "sydney_coords = [-33.8688, 151.2093] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe for venues\n",
    "First we'll need to create a dataframe with all Sydney suburbs and their corresponding coordinates. I use a community maintained dataframe where I have manually changed a few inaccurate coordinates for some suburbs. This dataframe contains all australian postcodes, so I merge it with another dataframe only containing Sydney postcodes and suburb names. I select the intersection of these two dataframes by using inner join, in order to get a dataframe with Sydney suburbs only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "7amf8LRTsxiZ",
    "outputId": "eea7b8f2-fb4b-448c-f3a9-6de24d3c42dc"
   },
   "outputs": [],
   "source": [
    "df_coord = pd.read_csv('https://github.com/saammirghorbani/australianpostcodes/raw/master/australian_postcodes.csv', usecols=['postcode', 'locality', 'long', 'lat'])\n",
    "df_subs = pd.read_csv('sydney_suburbs_postcodes.csv')\n",
    "\n",
    "\n",
    "# Name must be uppercase to match df_cords 'locality' column \n",
    "df_subs['locality'] = df_subs['locality'].str.upper()\n",
    "df_vnu = pd.merge(df_coord, df_subs, how='inner', on=['locality', 'postcode'])\n",
    "# Give better names to columns\n",
    "\n",
    "df_vnu.rename(columns={'locality':'suburb'}, inplace=True)\n",
    "\n",
    "df_vnu.dropna(inplace=True)\n",
    "\n",
    "print(df_vnu.shape)\n",
    "df_vnu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with this dataframe is that was found when clustering neighborhoods was that there are many neighboring suburbs that share the same coordinates. This means that we shouldn't use these coordinates to look for venues, as they would return the same venues for all the neighboring suburbs, and in the end it would incorrectly cluster them in the same group even though they most likely have different compositions of venues. \n",
    "\n",
    "As I mentioned, I have manually updated the coordinates on some of these suburbs, but since it would take a very long time to go through all we will simply keep a subset of suburbs that don't share coordinates for our clustering on venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop suburbs that have the same coordinates, keep the first occurence.\n",
    "df_vnu.drop_duplicates(subset=['long', 'lat'], keep='first', inplace=True)\n",
    "print(df_vnu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foursquare API\n",
    "In the next stage I want to get the most popular venues for each suburb. For this I make calls to Foursquare API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '5XXK41DFPB522NKMS0JSWEE0EQ0PC0JKPCZ14IYOFI3EWURX'#'CRALOD0T0CQVYXKE1VXXA0BMCD1HEIBU3VGFIFJBVRPP1W0J'#'2LPZZ10LCNP1RNKTFGKGUWRSIS5MXYSFU1F53VVZ3XASYOXO'#'5XXK41DFPB522NKMS0JSWEE0EQ0PC0JKPCZ14IYOFI3EWURX'  # your Foursquare ID\n",
    "CLIENT_SECRET = 'THPV0ULRUMHAAV3EOFXWTFPVGCCBPUTJZNOZQYFNPHBFZLYD'#'X4JPJATKV3LOVTPOW5T3OR33MO0XZFPXN03KC5W2EJ15FHGV'#'0CQ4R2URVJDAATZDYKU3OSWUSFTNFE2N45MMKGMWRRQ4JPMB'#  # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a method that given a suburb name with coordinates returns the top 100 veunes within a radius of 500 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_venues(suburb_names, longitudes, latitudes):\n",
    "    LIMIT = 100\n",
    "    radius = 500 \n",
    "    venues_list = []\n",
    "    for name, long, lat in zip(suburb_names, longitudes, latitudes): \n",
    "        \n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            long, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "\n",
    "         # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            long, \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "        print(name)\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Suburb', \n",
    "                  'Suburb Latitude', \n",
    "                  'Suburb Longitude', \n",
    "                  'Venue Category']\n",
    "    return(nearby_venues)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the top 100 venues for every suburb in our dataframe. This will take some time so I have created a CSV file containing the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if you want to make API calls to Foursquare and save to file\n",
    "#sydney_venues = get_venues(suburb_names=df_vnu['suburb'], longitudes=df_vnu['long'], latitudes=df_vnu['lat'])\n",
    "#sydney_venues.to_csv('sydney_venues.csv',index=False)\n",
    "sydney_venues = pd.read_csv('sydney_venues.csv')\n",
    "sydney_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data for K-Means clustering by encoding categorical variables (veunes) into a series of zeroes and ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_enc = pd.get_dummies(sydney_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add suburb column back to dataframe\n",
    "sydney_enc['Suburb'] = sydney_venues['Suburb'] \n",
    "\n",
    "# move suburb column to the first column\n",
    "sydney_enc = sydney_enc[['Suburb'] + list(sydney_enc.columns[:-1])]\n",
    "\n",
    "sydney_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want one entry per suburb, so we group the dataframe by suburb and use the mean to get a normalized value for the occurence of each venue category in that suburb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_grouped = sydney_enc.groupby('Suburb').mean().reset_index()\n",
    "sydney_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataframe will be ideal to use for K-means clustering of suburbs by similar venue categories. But to make sense of the patterns that the clusters are trying to capture we need another representation of this dataframe where we can see the top most common venues for each suburb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to sort the venues in descending order.\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Suburb']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "suburbs_venues_sorted = pd.DataFrame(columns=columns)\n",
    "suburbs_venues_sorted['Suburb'] = sydney_grouped['Suburb']\n",
    "\n",
    "for ind in np.arange(sydney_grouped.shape[0]):\n",
    "    suburbs_venues_sorted.iloc[ind, 1:] = return_most_common_venues(sydney_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "suburbs_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering\n",
    "We can now run the K-means clustering algorithm on the data with different values for K to see which one would be most suitable for our model. We use the sum of square distances from each point to its assigned center as a measure of how well the model is clustering the data. We get this as a score from the model's inertia and plot it for every value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducing results\n",
    "rnd_state = 1  \n",
    "distortions = []\n",
    "features = sydney_grouped.drop('Suburb', 1)\n",
    "kmeans_models = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "    kmeans_models.append(KMeans(n_clusters=k, random_state=rnd_state).fit(features))\n",
    "    distortions.append(kmeans_models[k-1].inertia_)\n",
    "    \n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the elbow method to visually determine the optimal value for K, we find that the inflection point happens where K = 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model\n",
    "We pick the model with K = 3 and merge the labels with the dataframe that shows the top venues for each suburb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusters = 3\n",
    "kmeans2 = kmeans_models[kclusters-1]\n",
    "sydney_grouped2 = sydney_grouped.copy()\n",
    "sydney_grouped2['labels'] = kmeans2.labels_\n",
    "df_final=suburbs_venues_sorted.join(sydney_grouped2.set_index('Suburb'), on=['Suburb'])\n",
    "df_final.drop(df_final.iloc[:, num_top_venues+1:-1], inplace=True, axis=1)\n",
    "df_final = df_final.join(df_vnu.set_index('suburb'), on=['Suburb'])\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House values\n",
    "I created a table over suburbs with their median house values by webscraping. Then I removed dollar signs and commas so that the value is displayed as an integer.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = pd.read_csv('sydney_houses_median_value.csv')\n",
    "# uppercase suburb names to match geojson entries\n",
    "df_house['suburb'] = df_house['suburb'].str.upper()\n",
    "df_house.drop(columns=['rank'], inplace=True)\n",
    "# format values for calculation\n",
    "df_house = df_house.replace(r'\\$','', regex=True) \n",
    "df_house = df_house.replace(r',','', regex=True)\n",
    "# make sure the values are of type int\n",
    "df_house['median_value_aud']=df_house['median_value_aud'].astype('int')\n",
    "df_house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data analysis\n",
    "Lets take a look at the distribution of house values by plotting them in a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Median house price')\n",
    "ax1.set_ylabel('value')\n",
    "ax1.boxplot(df_house['median_value_aud'])\n",
    "ax1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is an extreme outlier. Houses located in the Point Piper neighborhood are significantly more expensive (around \\\\$24,000,000 AUD) than houses in other neighborhoods, so let's remove it in order to better compare prices in a choropleth map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house.drop(df_house.index[df_house['suburb']=='POINT PIPER'], inplace=True)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Median house price')\n",
    "ax1.set_ylabel('value')\n",
    "ax1.boxplot(df_house['median_value_aud'])\n",
    "ax1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv('nsw_lga_crime_trends.csv', usecols=['Local Government Area', 'Offence type','Rate per 100,000 population Jan - Dec 2019'])\n",
    "\n",
    "df_crime.rename(columns={'Local Government Area':'region','Offence type':'type','Rate per 100,000 population Jan - Dec 2019':'crimes_2019'}, inplace=True)\n",
    "\n",
    "df_crime['region'] = df_crime['region'].str.upper()\n",
    "\n",
    "df_crime.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe includes crime data for all regions in the state of NSW, so I only select the Sydney regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_sydney_regions = ['BAYSIDE', 'BLACKTOWN','BURWOOD', 'CAMDEN', 'CAMPBELLTOWN', 'CANADA BAY', 'CANTERBURY-BANKSTOWN','CUMBERLAND'\n",
    "                  ,'FAIRFIELD','GEORGES RIVER','HORNSBY', 'HUNTERS HILL', 'INNER WEST','KU-RING-GAI','LANE COVE',\n",
    "                  'LIVERPOOL', 'MOSMAN', 'NORTH SYDNEY', 'NORTHERN BEACHES', 'PARRAMATTA', 'PENRITH', 'RANDWICK',\n",
    "                  'RYDE', 'STRATHFIELD', 'SUTHERLAND SHIRE', 'SYDNEY', 'THE HILLS SHIRE', 'WAVERLEY', 'WILLOUGHBY', 'WOOLLAHRA']\n",
    "df_crime['region'] = df_crime[df_crime['region'].isin(greater_sydney_regions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I add up all the crime rates per 100,000 population for each region and divide by 100,000 to get the crime rate as a probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum all crime rates in a region and group by region\n",
    "df_crime['crimes_2019'].replace(to_replace='nc', value=0, inplace=True)\n",
    "df_crime['crimes_2019'] = df_crime['crimes_2019'].astype(float)\n",
    "# get crime rate\n",
    "df_crime = df_crime.groupby(['region']).sum()/100000\n",
    "df_crime= df_crime.sort_values(by='crimes_2019',ascending=False)\n",
    "df_crime.reset_index(inplace=True)\n",
    "df_crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster composition\n",
    "To categorize the clusters we can look at the most common venues in them. We print the 1st, 2nd and 3rd most common venues in order of frequency found among the suburbs in the cluster, using the dataframe we created before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_column_indices = [1,2,3]\n",
    "required_column = [list(df_final.columns.values)[i] for i in required_column_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_series_0 = df_final.loc[df_final['labels'] == 0, df_final.columns[0:6]]\n",
    "print(\"Neighborhoods in cluster:\", df_final_series_0['Suburb'].size)\n",
    "for col in required_column:\n",
    "    print('------------------------------------------')\n",
    "    print(df_final_series_0[col].value_counts(ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most prominent venues in cluster 0 are yoga studios, fast food restaurants, and fish & chips shops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_series_1 = df_final.loc[df_final['labels'] == 1, df_final.columns[0:6]]\n",
    "print(\"Neighborhoods in cluster:\", df_final_series_1['Suburb'].size)\n",
    "for col in required_column:\n",
    "    print('------------------------------------------')\n",
    "    print(df_final_series_1[col].value_counts(ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most prominent venues in cluster 1 are cafés, pubs and pizza places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_series_2 = df_final.loc[df_final['labels'] == 2, df_final.columns[0:6]]\n",
    "print(\"Neighborhoods in cluster:\", df_final_series_2['Suburb'].size)\n",
    "for col in required_column:\n",
    "    print('------------------------------------------')\n",
    "    print(df_final_series_2[col].value_counts(ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most prominent venues in cluster 2 are parks, yoga studios and egyptian restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing clusters on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the neighborhoods with their labels on a map to get a geographical overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=sydney_coords, zoom_start=10)\n",
    "# set color scheme for the clusters\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, kclusters))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(df_final['lat'],df_final['long'], df_final['Suburb'], df_final['labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in the case of cluster 0 and cluster 1, there seems to be some sort of connection between the geographical location of the suburbs and their labels. Cluster 1 is mostly concentrated in the city center, while cluster 0 is further out and around the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choropleth map over house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dataframe from above containing median house values together with geojson data over Sydney suburbs we can visualize the values in a choropleth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DqNc5A-e2E5X",
    "outputId": "3f59c691-84e0-4905-df84-4ef1aea90b93"
   },
   "outputs": [],
   "source": [
    "with open('sydney_suburbs_geo.json') as json_data:\n",
    "    data = json.load(json_data)\n",
    "    \n",
    "threshold_scale = np.linspace(df_house['median_value_aud'].min(),\n",
    "                              df_house['median_value_aud'].max(),\n",
    "                              7, dtype=np.dtype('float64'))\n",
    "threshold_scale = threshold_scale.tolist() \n",
    "# make sure that the last value of the list is greater than the maximum value\n",
    "threshold_scale[-1] = threshold_scale[-1] + 1 \n",
    "\n",
    "# create a world map\n",
    "world_map = folium.Map(location=sydney_coords, zoom_start=11, tiles='OpenStreetMap')\n",
    "\n",
    "# generate choropleth map\n",
    "folium.Choropleth(\n",
    "    geo_data=data,\n",
    "    data=df_house,\n",
    "    columns=['suburb','median_value_aud'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.2,\n",
    "    legend_name='Median House value',\n",
    "    threshold_scale=threshold_scale,\n",
    "    reset=True\n",
    ").add_to(world_map)\n",
    "\n",
    "folium.LayerControl().add_to(world_map)\n",
    "# display map\n",
    "world_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Point Piper, we see that Watsons Bay and Elizabeth Bay (in Sydney Harbour) are the most expensive neighborhoods with most houses starting at \\\\$7,453,600 AUD\n",
    "\n",
    "A suburb which stands out is Duffys Forest (north). Being so far away from the city you'd expect it to have a similar house value as surrounding suburbs. The reason why that's not the case is that this suburb has a small population but several big mansions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choropleth map over crime rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the crime rate dataframe from above we load the geojson data for NSW regions and display the crime rates on a choropleth map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsw_lga_geo.json') as json_data:\n",
    "    data2 = json.load(json_data)\n",
    "\n",
    "# create a plain world map\n",
    "world_map2 = folium.Map(location=sydney_coords, zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "# generate choropleth map\n",
    "folium.Choropleth(\n",
    "    geo_data=data2,\n",
    "    data=df_crime,\n",
    "    columns=['region','crimes_2019'],\n",
    "    key_on='feature.properties.nsw_lga__3',\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.2,\n",
    "    legend_name='Crime rate in 2019',\n",
    "    reset=True\n",
    ").add_to(world_map2)\n",
    "\n",
    "folium.LayerControl().add_to(world_map2)\n",
    "# display map\n",
    "world_map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The city region of Sydney stands out as it has the highest crime rate (over 23%), followed by the outer western and southern regions (Penrith and Campbelltown). The crime rate seems to be lowest in the northern regions and around Sydney Harbour (excluding the city region), where it is below 6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Based on the results there are a couple of recommendations to make for someone planning on moving to or staying in Sydney. \n",
    "\n",
    "Roughly, we can summarize neighborhoods in cluster 0 as having lots of fast food restaurant options and yoga studios (interesting combination...). For anyone looking for any or both of these venues then the western and outer regions would be suitable. If you love cafés, pubs or pizza places then a neighborhood in cluster 1, which is focused around the city center, seems to be the best choice. Over 80% of the suburbs here have café as their most common venue. If you are however looking for parks, yoga studios or egyptian restuarants then neighborhoods in cluster 3 seem to be good choices. These neighborhoods are spread out but can be found in various areas (see cluster map above).\n",
    "\n",
    "Living expenses are affected by many factors but looking at median house values alone we can conclude that house values in coastal areas, eastern suburbs, and neighborhoods surrounding Chatswood and Gordon are higher than in areas further inland. One should expect to pay at least \\$1,500,000 AUD for owning a house here. \n",
    "\n",
    "For someone concerned about crime, the rates from 2019 are highest in the city region and lowest in the northern regions. The crime rate is generally higher in the west than in the east. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "the-battle-of-neighborhoods.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
